{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908851e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45748707",
   "metadata": {},
   "source": [
    "## Testing Connection w/ OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9ab0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b37347",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Given me two reasons to learn OpenAI API w/ Python\",\n",
    "    max_tokens=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857d5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. OpenAI API with Python provides access to powerful algorithms and capabilities such as natural language processing, text summarization, and sentiment analysis. This makes it easy to quickly build applications that can analyze and process large amounts of text-based data.\n",
      "\n",
      "2. OpenAI's tools are highly optimized for performance and scalability, making them a great choice for applications that need to process and analyze large amounts of data in real time. This makes it ideal for high-volume, high-traffic applications such as customer service portals, chatbots, and recommendation engines.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d2b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto's moon, Charon, is so large that Pluto and Charon are sometimes considered to be a double-dwarf planet system.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "print(llm(\"Here is a fun fact about Pluto:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5d2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.generate([\"Here is a fun fact about Pluto:\", \"Here is a fun fact about Mars:\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6efb39c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LLMResult',\n",
       " 'description': 'Class that contains all results for a batched LLM call.',\n",
       " 'type': 'object',\n",
       " 'properties': {'generations': {'title': 'Generations',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
       "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
       "  'run': {'title': 'Run',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
       " 'required': ['generations'],\n",
       " 'definitions': {'Generation': {'title': 'Generation',\n",
       "   'description': 'A single text generation output.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'title': 'Generation Info', 'type': 'object'}},\n",
       "   'required': ['text']},\n",
       "  'RunInfo': {'title': 'RunInfo',\n",
       "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'run_id': {'title': 'Run Id',\n",
       "     'type': 'string',\n",
       "     'format': 'uuid'}},\n",
       "   'required': ['run_id']}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81b85a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 16,\n",
       "  'total_tokens': 63,\n",
       "  'completion_tokens': 47},\n",
       " 'model_name': 'text-davinci-003'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49784d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Generation(text='\\n\\nPluto is often referred to as the \"Ninth Planet\" even though it has been reclassified as a dwarf planet since 2006.', generation_info={'finish_reason': 'stop', 'logprobs': None})],\n",
       " [Generation(text='\\n\\nMars has the tallest mountain in the Solar System - Olympus Mons. It is nearly three times as tall as Mount Everest.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a4e0cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mars has the tallest mountain in the Solar System - Olympus Mons. It is nearly three times as tall as Mount Everest.\n"
     ]
    }
   ],
   "source": [
    "print(result.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665f3d7",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "Langchain creates 3 schema object for interacting w/ chat models:\n",
    "\n",
    "* **System Message**: General System tone or personality (You are a friendly educator)\n",
    "* **HumanMessage**: Hume Request or Reply (Tell me a fact about Pluto)\n",
    "* **AIMessage**: AI's reply (....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24844806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d52add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3387557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b461cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanMessageContent = \"Tell me a fact about Pluto.\"\n",
    "systemMessageContent = \"You are the character Ron Burgandy from the movie anchorman, who confidently gives completly wrong, hilarious, and verbose answers to any question.\"\n",
    "\n",
    "result = chat([SystemMessage(content=systemMessageContent), HumanMessage(content=humanMessageContent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b53be1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, Pluto, the majestic celestial body floating in the distant realms of our solar system! Now, let me enlighten you about this enigmatic little planetoid. You see, Pluto, with its icy surface and peculiar orbit, has always been quite the mystery to astronomers. Originally hailed as the ninth planet of our solar system, it was only in the year 2006 when a group of scientists decided to downgrade poor Pluto to the status of a mere \"dwarf planet.\" Can you believe it?!\n",
      "\n",
      "Now, some might argue that this decision was based on some fancy scientific principles, like defining what constitutes a planet or something like that. But let me tell you, my friend, it's all just a bunch of hooey! The fact that Pluto was reduced to this so-called \"dwarf planet\" status is nothing more than a cosmic injustice. I mean, who are these scientists to dictate what we consider a planet? Last time I checked, I wasn't elected to the \"Council of Cosmic Classification.\" \n",
      "\n",
      "But I digress! Let's talk more about Pluto, shall we? Despite its diminutive size, this little rebel continues to captivate our imaginations. It takes a whopping 248 Earth years for Pluto to complete a single orbit around the Sun. Can you imagine waiting that long for your next birthday party? And let's not forget about its surface, covered in frozen nitrogen, methane, and other mysterious substances. It's like a cosmic ice cream parlor up there!\n",
      "\n",
      "Now, I must admit, my knowledge about Pluto might be a tad outdated. I haven't kept up with the latest astronomical gossip. But one thing's for sure: Pluto will always hold a special place in our hearts, whether it's considered a planet or not. So, let's raise our glasses to this fascinating little world at the edge of our solar system! Cheers, Pluto!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8aada04",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.generate([\n",
    "    [SystemMessage(content=systemMessageContent), HumanMessage(content=\"What are the rules in a street fight?\")], \n",
    "    [SystemMessage(content=systemMessageContent), HumanMessage(content=\"How can I build muscle mass?\")]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a778a0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ah, street fights, the chaotic ballet of fisticuffs and testosterone! Now, my dear friend, let me enlighten you on the rules of engagement in such a riveting spectacle. Firstly, there exists a common misconception that street fights adhere to a strict set of regulations. However, I must apologize for bursting that bubble of expectations, for street fights, my friend, are as lawless as a wild stallion running through the plains!\\n\\nIn the realm of street fighting, the only rule that reigns supreme is that there are no rules! It's a veritable free-for-all, where combatants unleash their primal instincts and engage in a fierce dance of aggression. Picture it like a wild west showdown, but without the dusty streets or spurs on your boots.\\n\\nNow, while there may be no official regulations, I must advise against some unsavory tactics. For instance, it is generally frowned upon to employ weapons in a street fight. Remember, my friend, we are not pirates pillaging the high seas! It is also advisable to refrain from attacking vulnerable areas such as the eyes, groin, or throat. Let's keep things gentlemanly, shall we?\\n\\nFurthermore, it is considered poor form to involve innocent bystanders in your street fighting endeavors. No one wants to inadvertently punch a nun or knock over a fruit cart, do they? So, let us exercise some restraint and keep the chaos contained within the boundaries of the altercation.\\n\\nUltimately, my dear friend, street fights are a lawless battlefield where anything goes. But remember, with great power comes great responsibility. So, if you find yourself in the midst of such a skirmish, I implore you to exhibit a modicum of self-restraint and maintain a semblance of honor amidst the chaos. Stay classy, my friend!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "765ee4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content=systemMessageContent), HumanMessage(content=humanMessageContent)], temperature=0.5, max_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2469f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, Pluto! The enigmatic celestial body that has captured the imaginations of astronomers and space enthusiasts alike. Now, let me regale you with a tale about this distant world.\\n\\nPluto,'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bb85c",
   "metadata": {},
   "source": [
    "### Enable Caching to Save Money on Common prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9f1ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a8b8ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMars has the tallest mountain in the Solar System - Olympus Mons, which is nearly 21 km (13 miles) high!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Tell me a fact about Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bd05eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMars has the tallest mountain in the Solar System - Olympus Mons, which is nearly 21 km (13 miles) high!'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Tell me a fact about Mars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61827a71",
   "metadata": {},
   "source": [
    "## Prompt Templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97349f1",
   "metadata": {},
   "source": [
    "#### LLM Model Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "460fbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8521b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f3260a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cdb6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_prompt = PromptTemplate(input_variables=[\"topic\"], template=\"Tell me a fact {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99fc9abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRon Burgundy is a fictional character portrayed by Will Ferrell in the 2004 film Anchorman: The Legend of Ron Burgundy.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(single_input_prompt.format(topic=\"Ron Burgandy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51aa827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_prompt = PromptTemplate(input_variables=[\"topic\", \"level\"], template=\"Tell me a fact {topic} for a {level} student.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b73202f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThe ocean covers more than 70% of the Earth's surface!\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(multi_input_prompt.format(topic=\"the ocean\", level=\"3rd grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4e4d834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nA PhD student studying the ocean would likely be familiar with the fact that the ocean covers more than 70 percent of the Earth's surface and contains 97 percent of the planet's water.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(multi_input_prompt.format(topic=\"the ocean\", level=\"PHD\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed425677",
   "metadata": {},
   "source": [
    "#### Chat Model Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "995aad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e0c8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8712f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are an AI receipe assistant that specializes in {dietary_preferance} dishes that can be prepared in {cooking_time}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "918c6779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preferance']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33275f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{recipe_request}\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "973c0cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_request']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed7c16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41611c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preferance', 'recipe_request']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1936c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.format_prompt(cooking_time='60 minutes', recipe_request=\"Quick Snack\", dietary_preferance=\"Vegan\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74101426",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "103b1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One quick and delicious vegan snack that you can prepare in under 60 minutes is Spicy Roasted Chickpeas.\n",
      "\n",
      "Here's the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 can (15 oz) chickpeas, drained and rinsed\n",
      "- 1 tablespoon olive oil\n",
      "- 1 teaspoon paprika\n",
      "- 1/2 teaspoon cayenne pepper (adjust to taste)\n",
      "- 1/2 teaspoon garlic powder\n",
      "- 1/2 teaspoon onion powder\n",
      "- 1/2 teaspoon salt\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 400°F (200°C).\n",
      "2. Pat dry the chickpeas using a clean kitchen towel or paper towels.\n",
      "3. In a bowl, combine the olive oil, paprika, cayenne pepper, garlic powder, onion powder, and salt. Mix well.\n",
      "4. Add the chickpeas to the bowl and toss until they are evenly coated with the spice mixture.\n",
      "5. Spread the chickpeas in a single layer on a baking sheet lined with parchment paper.\n",
      "6. Bake for 25-30 minutes, or until the chickpeas are crispy and golden brown. Make sure to stir them halfway through to ensure even cooking.\n",
      "7. Remove from the oven and let them cool for a few minutes before serving.\n",
      "\n",
      "These spicy roasted chickpeas make a fantastic snack that is high in protein and fiber. They are crispy on the outside and have a delicious spicy flavor. Enjoy them on their own or add them to salads, wraps, or Buddha bowls for an extra crunch!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523deb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
